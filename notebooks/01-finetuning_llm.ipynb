{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc4c2de-303e-4275-9be6-0ca31301a4c2",
   "metadata": {},
   "source": [
    "# Finetuning for Question Answering Using LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1e87da-898f-427b-a51f-5d38e19401fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install required packages\n",
    "!pip install -q bitsandbytes\n",
    "!pip install -q --upgrade transformers \n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q datasets\n",
    "!pip install -q --upgrade tensorboard\n",
    "!pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79211d63-32c3-4447-977b-2539d9baf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from peft import prepare_model_for_int8_training\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c9f3aa-dead-4b7d-8a0a-0163a97a695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check for GPU availibility \n",
    "display(torch.cuda.is_available())\n",
    "\n",
    "display(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7464874-021c-41cc-a422-54fe1ebda019",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249cb892-7930-4cd7-bdfc-2b0f7cf9d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at google/flan-t5-base and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer \n",
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03819743-f068-429d-8813-ab151c251289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 87145728 || all params: 247577856 || trainable%: 35.199322511299236\n"
     ]
    }
   ],
   "source": [
    "# code from [1]\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5789f4df-0f4a-41e4-beed-6afccf8107a9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3921229a-b3b9-4166-88f2-dc87df9bd3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>generated_answers</th>\n",
       "      <th>extracted_answers</th>\n",
       "      <th>abstracted_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of the `ifconfig` command ...</td>\n",
       "      <td>The `ifconfig` command is used to configure th...</td>\n",
       "      <td>The ifconfig command in Linux is used to confi...</td>\n",
       "      <td>ipprotocol ipv4  proto         frompor...</td>\n",
       "      <td>all rules are applied only to the driver inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How would you add a static IP to a Linux machine?</td>\n",
       "      <td>You can add a static IP to a Linux machine by ...</td>\n",
       "      <td>To add a static IP to a Linux machine, you wil...</td>\n",
       "      <td>this guide will walk you through getting your ...</td>\n",
       "      <td>sudo ip link del wg0 osxwindows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is WireGuard?</td>\n",
       "      <td>WireGuard is an open-source VPN solution that ...</td>\n",
       "      <td>WireGuard is a software application that prote...</td>\n",
       "      <td>relay node the relay needs to have v6 forwardi...</td>\n",
       "      <td>tunneling mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How would you install WireGuard on a Linux mac...</td>\n",
       "      <td>Typically, you would use a package manager suc...</td>\n",
       "      <td>To install WireGuard on a Linux machine, you w...</td>\n",
       "      <td>relay node the relay needs to have v6 forwardi...</td>\n",
       "      <td>shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you check the current IP address of you...</td>\n",
       "      <td>You can use the `ip addr show` command to disp...</td>\n",
       "      <td>In Linux, you can check the current IP address...</td>\n",
       "      <td>ipprotocol ipv4  proto         frompor...</td>\n",
       "      <td>ip_protocol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  What is the purpose of the `ifconfig` command ...   \n",
       "1  How would you add a static IP to a Linux machine?   \n",
       "2                                 What is WireGuard?   \n",
       "3  How would you install WireGuard on a Linux mac...   \n",
       "4  How do you check the current IP address of you...   \n",
       "\n",
       "                                             answers  \\\n",
       "0  The `ifconfig` command is used to configure th...   \n",
       "1  You can add a static IP to a Linux machine by ...   \n",
       "2  WireGuard is an open-source VPN solution that ...   \n",
       "3  Typically, you would use a package manager suc...   \n",
       "4  You can use the `ip addr show` command to disp...   \n",
       "\n",
       "                                   generated_answers  \\\n",
       "0  The ifconfig command in Linux is used to confi...   \n",
       "1  To add a static IP to a Linux machine, you wil...   \n",
       "2  WireGuard is a software application that prote...   \n",
       "3  To install WireGuard on a Linux machine, you w...   \n",
       "4  In Linux, you can check the current IP address...   \n",
       "\n",
       "                                   extracted_answers  \\\n",
       "0          ipprotocol ipv4  proto         frompor...   \n",
       "1  this guide will walk you through getting your ...   \n",
       "2  relay node the relay needs to have v6 forwardi...   \n",
       "3  relay node the relay needs to have v6 forwardi...   \n",
       "4          ipprotocol ipv4  proto         frompor...   \n",
       "\n",
       "                                  abstracted_answers  \n",
       "0  all rules are applied only to the driver inter...  \n",
       "1                    sudo ip link del wg0 osxwindows  \n",
       "2                                     tunneling mode  \n",
       "3                                              shell  \n",
       "4                                        ip_protocol  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data \n",
    "nexodus_qa_df = pd.read_csv('../data/results/nexodus_qa_df.csv', index_col=0)\n",
    "\n",
    "display(nexodus_qa_df.head())\n",
    "display(nexodus_qa_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c62f38-6ae6-4050-9976-bf3c1f2b003d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train test split\n",
    "train_df = nexodus_qa_df.sample(frac=0.8,random_state=42)\n",
    "test_df = nexodus_qa_df.drop(train_df.index)\n",
    "\n",
    "display(len(train_df))\n",
    "display(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e004295-8aa3-43b1-a417-25c447c43a80",
   "metadata": {},
   "source": [
    "## Generate Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5364524e-34b4-4704-b76e-0fa9daf1223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from [2]\n",
    "def get_answers(question, context=\"\"):\n",
    "    question_context = f\"Question: ## {question} ##\\n Context: ## {context} ##\"\n",
    "    input_ids = tokenizer(question_context, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=1000, do_sample=True, top_p=1)\n",
    "    answer = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ceb8c9-ab5b-4cab-8fa6-f73f9f85d290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In Linux's linux framework, setting up an IP address will create a small temporary port for local data.\",\n",
       " 'wireguards',\n",
       " 'To store a copy of the resolution of the kernel configuration files',\n",
       " 'the process to synchronize a remote directory',\n",
       " \"To do this, you'd first need to add an ethernet connection to the IP address and the host computer.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate answers to test questions \n",
    "pretrained_answers = []\n",
    "for i, row in test_df.iterrows():\n",
    "    pretrained_answers.append(get_answers(row.questions))\n",
    "\n",
    "# add to test_df\n",
    "test_df['pretrained_answers'] = pretrained_answers\n",
    "pretrained_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac23d8-5b40-4630-9d3d-ef8d01f63011",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa40ca96-476d-4e1a-a37a-0e80eba8bc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'answers', 'generated_answers', 'extracted_answers', 'abstracted_answers', '__index_level_0__'],\n",
       "    num_rows: 80\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert training data to dataset object\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afff1c74-e077-4f38-b678-d133a6f3a671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121d5e8c95f54c7383ab10f9c8d00793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7475a61553d4980be2f3c74891afbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 29\n",
      "Max target length: 80\n"
     ]
    }
   ],
   "source": [
    "# code adapted from [1], [2]\n",
    "\n",
    "# tokenize questions and answers\n",
    "tokenized_questions = train_data.map(lambda x: tokenizer(x[\"questions\"],\n",
    "                                     truncation=True),\n",
    "                                     batched=True,\n",
    "                                     remove_columns=['questions', 'answers', 'generated_answers', 'extracted_answers', 'abstracted_answers'])\n",
    "\n",
    "tokenized_answers = train_data.map(lambda x: tokenizer(x[\"answers\"],\n",
    "                                   truncation=True),\n",
    "                                   batched=True,\n",
    "                                   remove_columns=['questions', 'answers'])\n",
    "\n",
    "# inputs/outputs longer than the max with be concatenated, inputs/outputs shorter will be padded\n",
    "input_lengths = [len(x) for x in tokenized_questions[\"input_ids\"]]\n",
    "max_source_length = int(np.percentile(input_lengths, 100))\n",
    "print(f'Max source length: {max_source_length}')\n",
    "      \n",
    "output_lengths = [len(x) for x in tokenized_answers[\"input_ids\"]]\n",
    "max_target_length = int(np.percentile(output_lengths, 100))\n",
    "print(f'Max target length: {max_target_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b79396f-b05c-4dbe-8427-44f16dcf8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from [1]\n",
    "def preprocess_function(example):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [f\"Question: ## {q} ##\\n Context: ## {c} ##\" for q, c in zip(example[\"questions\"], example[\"extracted_answers\"])] # use extracted answers for context\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs,\n",
    "                             max_length=max_source_length,\n",
    "                             padding=\"max_length\",\n",
    "                             truncation=True)\n",
    "    \n",
    "    outputs = [\"Answer: \" + item for item in example[\"answers\"]]\n",
    "    \n",
    "    labels = tokenizer(text_target=outputs,\n",
    "                       max_length=max_target_length,\n",
    "                       padding=\"max_length\",\n",
    "                       truncation=True)\n",
    "  \n",
    "    \n",
    "    labels[\"input_ids\"] = [\n",
    "    [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "                          ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52aa28c8-e966-4c56-a7e3-aad1308e4ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6a11c1a8054225ac8f3dde2b085805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 80\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_data = train_data.map(preprocess_function,\n",
    "                                     batched=True,\n",
    "                                     remove_columns=[\"questions\", \"answers\", 'generated_answers', 'extracted_answers', 'abstracted_answers' ])\n",
    "preprocessed_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6453d-71f5-499a-a323-1a1d6cd32b41",
   "metadata": {},
   "source": [
    "## Finetune with LoRA and 8-bit Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "549beec2-fe63-4c9d-a440-53bbc37fc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data collator which pads inputs and labels\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100, # ignore tokenizer pad token in the loss\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce090f7-1d47-4fa7-ae77-c8d35ed93234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"models/lora-flan-t5-base\"\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    "    )\n",
    "\n",
    "# prepare int-8 model for training\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "\n",
    "# define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=preprocessed_train_data\n",
    ")\n",
    "\n",
    "# set to false during training\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "226b15f0-3204-4bac-bd34-de8f1df09adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=1.9549897766113282, metrics={'train_runtime': 43.3856, 'train_samples_per_second': 18.439, 'train_steps_per_second': 2.305, 'total_flos': 34509658521600.0, 'train_loss': 1.9549897766113282, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7e589f-5727-4e62-828f-83153970694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f100e5958ae24df8b419b1f4311bde25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.bin:   0%|          | 0.00/7.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/exyou/nexodus-flan-t5/commit/4b159c14ebdab7c66aee0a85a75477d3e4ad9c59', commit_message='Upload model', commit_description='', oid='4b159c14ebdab7c66aee0a85a75477d3e4ad9c59', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push to HuggingFace\n",
    "!notebook_login()\n",
    "nexodus_flan_T5.push_to_hub('exyou/nexodus-flan-t5')\n",
    "# save LoRA model to local directory\n",
    "nexodus_flan_T5.save_pretrained('../models/nexodus-flan-t5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf8f9a0-26d9-49db-aceb-276c3d2765f8",
   "metadata": {},
   "source": [
    "## Load Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3522d540-afa9-47ba-bf83-099a7043108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, '../models/nexodus-flan-t5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d5ea99-8084-406c-8507-9446ce37dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Answer: You would add a static IP to a Linux machine using the net-add path command, e.g. net-add link add [net_add 0].',\n",
       " 'Answer: WireGuard is the name of several programs. Most programs are hosted on the same servers, allowing IP addresses to be displayed.',\n",
       " 'Answer: The /etc/resolv.conf file is used to set up the default resolving configuration files, such as /etc/resolv.conf using the /etc/resolv.conf plug-in.',\n",
       " 'Answer: The ip command is used to configure packet forwarding, like a tunnel or an IP address, using its iproute command. This command is used to specify incoming traffic of IP addresses.',\n",
       " 'Answer: You would add a static IP to a Linux machine using the ip addr addr show command and then add the IP with the \"ip addr addr add\" command.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_answers = []\n",
    "for i, row in test_df.iterrows():\n",
    "    finetuned_answers.append(get_answers(row.questions))\n",
    "    \n",
    "test_df['finetuned_answers'] = finetuned_answers\n",
    "finetuned_answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9401564b-bd67-4219-b250-8ce1226bdde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>generated_answers</th>\n",
       "      <th>extracted_answers</th>\n",
       "      <th>abstracted_answers</th>\n",
       "      <th>pretrained_answers</th>\n",
       "      <th>finetuned_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How would you add a static IP to a Linux machine?</td>\n",
       "      <td>You can add a static IP to a Linux machine by ...</td>\n",
       "      <td>To add a static IP to a Linux machine, you wil...</td>\n",
       "      <td>this guide will walk you through getting your ...</td>\n",
       "      <td>sudo ip link del wg0 osxwindows</td>\n",
       "      <td>In Linux's linux framework, setting up an IP a...</td>\n",
       "      <td>Answer: You would add a static IP to a Linux m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is WireGuard?</td>\n",
       "      <td>WireGuard is an open-source VPN solution that ...</td>\n",
       "      <td>WireGuard is a software application that prote...</td>\n",
       "      <td>relay node the relay needs to have v6 forwardi...</td>\n",
       "      <td>tunneling mode</td>\n",
       "      <td>wireguards</td>\n",
       "      <td>Answer: WireGuard is the name of several progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the purpose of the `/etc/resolv.conf` ...</td>\n",
       "      <td>The `/etc/resolv.conf` file is used to configu...</td>\n",
       "      <td>The /etc/resolv.conf file in Linux is used to ...</td>\n",
       "      <td>in conclusion in the short term since we are n...</td>\n",
       "      <td>cross organization device sharing</td>\n",
       "      <td>To store a copy of the resolution of the kerne...</td>\n",
       "      <td>Answer: The /etc/resolv.conf file is used to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the purpose of the `ip` command in Linux?</td>\n",
       "      <td>The `ip` command is a powerful tool for manipu...</td>\n",
       "      <td>The ip command in Linux is used to connect to ...</td>\n",
       "      <td>ipprotocol ipv4  proto         frompor...</td>\n",
       "      <td>starting port range</td>\n",
       "      <td>the process to synchronize a remote directory</td>\n",
       "      <td>Answer: The ip command is used to configure pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How would you add a static IP to a Linux machine?</td>\n",
       "      <td>You can add a static IP to a Linux machine by ...</td>\n",
       "      <td>To add a static IP to a Linux machine, you wil...</td>\n",
       "      <td>this guide will walk you through getting your ...</td>\n",
       "      <td>sudo ip link del wg0 osxwindows</td>\n",
       "      <td>To do this, you'd first need to add an etherne...</td>\n",
       "      <td>Answer: You would add a static IP to a Linux m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            questions  \\\n",
       "1   How would you add a static IP to a Linux machine?   \n",
       "2                                  What is WireGuard?   \n",
       "14  What is the purpose of the `/etc/resolv.conf` ...   \n",
       "20  What is the purpose of the `ip` command in Linux?   \n",
       "21  How would you add a static IP to a Linux machine?   \n",
       "\n",
       "                                              answers  \\\n",
       "1   You can add a static IP to a Linux machine by ...   \n",
       "2   WireGuard is an open-source VPN solution that ...   \n",
       "14  The `/etc/resolv.conf` file is used to configu...   \n",
       "20  The `ip` command is a powerful tool for manipu...   \n",
       "21  You can add a static IP to a Linux machine by ...   \n",
       "\n",
       "                                    generated_answers  \\\n",
       "1   To add a static IP to a Linux machine, you wil...   \n",
       "2   WireGuard is a software application that prote...   \n",
       "14  The /etc/resolv.conf file in Linux is used to ...   \n",
       "20  The ip command in Linux is used to connect to ...   \n",
       "21  To add a static IP to a Linux machine, you wil...   \n",
       "\n",
       "                                    extracted_answers  \\\n",
       "1   this guide will walk you through getting your ...   \n",
       "2   relay node the relay needs to have v6 forwardi...   \n",
       "14  in conclusion in the short term since we are n...   \n",
       "20          ipprotocol ipv4  proto         frompor...   \n",
       "21  this guide will walk you through getting your ...   \n",
       "\n",
       "                   abstracted_answers  \\\n",
       "1     sudo ip link del wg0 osxwindows   \n",
       "2                      tunneling mode   \n",
       "14  cross organization device sharing   \n",
       "20                starting port range   \n",
       "21    sudo ip link del wg0 osxwindows   \n",
       "\n",
       "                                   pretrained_answers  \\\n",
       "1   In Linux's linux framework, setting up an IP a...   \n",
       "2                                          wireguards   \n",
       "14  To store a copy of the resolution of the kerne...   \n",
       "20      the process to synchronize a remote directory   \n",
       "21  To do this, you'd first need to add an etherne...   \n",
       "\n",
       "                                    finetuned_answers  \n",
       "1   Answer: You would add a static IP to a Linux m...  \n",
       "2   Answer: WireGuard is the name of several progr...  \n",
       "14  Answer: The /etc/resolv.conf file is used to s...  \n",
       "20  Answer: The ip command is used to configure pa...  \n",
       "21  Answer: You would add a static IP to a Linux m...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check to ensure results are saved to test_df\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67b6685f-b552-45c1-93db-0192ff5a536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test_df to csv file\n",
    "test_df.to_csv(\"../data/results/test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e117c87-f7b7-4294-ae1e-26cd1b90f492",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde99dd-de18-404a-adf6-84446b580bec",
   "metadata": {},
   "source": [
    "1. https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/peft-flan-t5-int8-summarization.ipynb\n",
    "\n",
    "2. https://github.com/redhat-et/foundation-models-for-documentation/blob/master/notebooks/finetune/Flan-T5-3B/RosaQA.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
